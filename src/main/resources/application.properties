server.servlet.context-path=/novel
spring.http.encoding.charset=UTF-8
debug=false
server.port=80

#mybatis.config-location=classpath:mybatis-config.xml
#mybatis mapper文件的位置
mybatis.mapper-locations=classpath*:com/trojan/mapper/*.xml
#扫描pojo类的位置,在此处指明扫描实体类的包，在mapper中就可以不用写pojo类的全路径名了
mybatis.type-aliases-package=com.trojan.entity

#================数据库配置==========
#数据库连接类型
jdbc.type=mysql
#数据库地址
spring.datasource.url=jdbc:mysql://47.107.80.167:3306/rs?serverTimezone=GMT&useUnicode=true&characterEncoding=UTF-8
#数据库用户名
spring.datasource.username=root
#数据库密码
spring.datasource.password=root
#数据库驱动
spring.datasource.driver-class-name=com.mysql.jdbc.Driver

##redis配置
##Redis服务器地址
#spring.redis.host=127.0.0.1
##Redis服务器连接端口
#spring.redis.port=6379
##Redis数据库索引（默认为0）
#spring.redis.database=0  
##连接池最大连接数（使用负值表示没有限制）
#spring.redis.jedis.pool.max-active=50
##连接池最大阻塞等待时间（使用负值表示没有限制）
#spring.redis.jedis.pool.max-wait=3000
##连接池中的最大空闲连接
#spring.redis.jedis.pool.max-idle=20
##连接池中的最小空闲连接
#spring.redis.jedis.pool.min-idle=2
##连接超时时间（毫秒）
#spring.redis.timeout=5000


#sql展示
logging.level.root=info
logging.level.sql=debug
logging.pattern.file=%d{yyyy/MM/dd-HH:mm} [%thread] %-5level %logger- %msg%n
#spring.thymeleaf.cache=false
spring.mvc.view.prefix=classpath:/templates/
spring.mvc.view.suffix=.html


##============== kafka ===================
## 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=127.0.0.1:9092
#
##=============== provider  =======================
#
#spring.kafka.producer.retries=0
## 每次批量发送消息的数量
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
#
## 指定消息key和消息体的编解码方式
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#
##=============== consumer  =======================
## 指定默认消费者group id
#spring.kafka.consumer.group-id=test-consumer-group
#
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
#
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer